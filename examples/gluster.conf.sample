[hosts]
10.70.46.13
10.70.46.15
10.70.46.17
10.70.46.19
#------------------------------

# Generic section [devices] is applicable to all the hosts listed in the [hosts]
# section. However, if sections of hosts [hostname] or [ip-address] is present,
# then the data in generic sections like [devices] are ignored. Host specific
# data take precedence.

# [devices]
# /dev/sda
# /dev/vdb
# /dev/vda
#------------------------------

# Section [disktype] specifies which disk configuration is used while
# setting up the backend. Supports RAID 10, RAID 6 and JBOD configurations.
# If this field is left empty, it will be by default taken as JBOD.
# This is common for all the hosts.

# [disktype]
# raid6
#------------------------------

# Section [diskcount] specifies the number of data disks in the setup. This is a
# mandatory field if the disk configuration specified is either RAID 10 or
# RAID 6 and will be ignored if architecture is JBOD. This is host specific
# data.

# [diskcount]
# 10
#------------------------------

# Section [stripesize] specifies the stripe_unit size in KB. This is a mandatory
# field if disk configuration is RAID 6. If this is not specified in case of
# RAID 10 configurations, it will take the default value 256K. This field is
# not necessary for JBOD configuration of disks. Do not add any suffixes like
# K, KB, M, etc.This is host specific data.

# [stripesize]
# 128
#------------------------------

# vg names for the above devices
# The number of vgs in the [vgs] should match the devices

# [vgs]
# CUSTOM_vg
#------------------------------

# pool names for the above volume groups
# The number of pools listed in the [pools] section should match the number of
# vgs.

# [pools]
# CUSTOM_pool
#------------------------------

# lv names for the above volume groups
# The number of logical volumes listed in the [lvs] section should match the
# number of vgs.

# [lvs]
# CUSTOM_lv
#-------------------------------

# Brick mountpoints for the logical volumes
# The number of mountpoints should match the number of logical volumes listed
# above.
# IMP: If only gluster deployment is to be done and not back-end setup, just
# give this data about the hosts specified in the [hosts] section along
# with the client data.

# [mountpoints]
# /gluster/brick
#-------------------------------

# brick_dir is the directory which is to be used as brick while creating the
# volume. A mountpoint cannot be used as a brick directory, so brick_dir
# specifies the directory to be made inside the LV mount point that will be
# used as a brick.
# This field can be left empty in which case a directory will be created
# inside the mountpoint with a default name. If backend setup is not being done
# this field will be ignored.

# [brick_dir]
# gluster_brick


# Host specific data are to be given as follows

[10.70.46.13]
devices=/dev/sdb,/dev/vdb,/dev/vda
vgs=CUSTOM_vg1,CUSTOM_vg2,CUSTOM_vg3
pools=CUSTOM_pool1,CUSTOM_pool2,CUSTOM_pool3
lvs=CUSTOM_lv1,CUSTOM_lv2,CUSTOM_lv3
mountpoints=/gluster/brick1,/gluster/brick2,/gluster/brick3
brick_dir=glusterbrick

[10.70.46.15]
devices=/dev/vdc,/dev/vdb
vgs=CUSTOM_vg1,CUSTOM_vg2
pools=CUSTOM_pool1,CUSTOM_pool2
lvs=CUSTOM_lv1,CUSTOM_lv2
mountpoints=/gluster/brick1,/gluster/brick2

[10.70.46.17]
devices=/dev/vdc,/dev/vdb
vgs=CUSTOM_vg1,CUSTOM_vg2
pools=CUSTOM_pool1,CUSTOM_pool2
lvs=CUSTOM_lv1,CUSTOM_lv2
mountpoints=/gluster/brick1,/gluster/brick2

[10.70.46.19]
devices=/dev/vdb
vgs=CUSTOM_vg1
pools=CUSTOM_pool1
lvs=CUSTOM_lv1
mountpoints=/gluster/brick1
#----------------------------------

# The section peer specifies the configurations for the Trusted Storage
# Pool managament(TSP)

# This section helps in making all the hosts specified in the section 'hosts'
# to either probe each other making the TSP or detach all of them from TSP

# The only option in this section is the option names 'manage' which can have
# it's values to be  either probe or detach

[peer]
manage=probe
# manage=detach

#-----------------------------------
# The section volume specifies the configuration options for the volume.

# 'action' option specifies what action id to be performed in the volume.
# The choices are: [create, delete, add-brick, remove-brick, rebalance].

# If delete is provided all the options other than 'volname' will be ignored.

# If add-brick or remove-brick is chosen, extra option bricks with a
# comma seperated list of brick names(in the format <hostname>:<brick path>
# should be provided.

# In case of remove-brick and rebalance, 'state' option should also
# be provided. Choices for 'state' are:
# For remove-brick: [start, stop, commit, force]
# For rebalance: [start, stop, fix-layout]

# 'volname' option specifies the volume name. Default is glustervol
#  If the user wishes to do just a volume operation, she can omit the
#  'hosts' section if the volname is provided in the format
#  <hostname>:<volname>, where hostname is the hostname or IP of one of
#  the nodes in the cluster

#  IMP: Only single volume creation/deletion/configuration is supported
#  as of now.

# 'transport' option specifies the transport type. Default is tcp. Options are
# tcp or rdma or tcp,rdma

# 'replica' option will specify if the volume should be of type replica or not.
# options are yes and no. Default is no.
# If 'replica' is given as yes, 'replica_count' should be given.
# Option 'arbiter_count' is optional.

# 'disperse' option will specify if the volume should be of type disperse.
# options are yes and no. Default is no.
# 'disperse_count' is optional even if the 'disperse' is yes. if not specified,
# the number of bricks specified in the command line is taken as the
# disperse_count value.
# If 'redundancy_count' is not specified, and if 'disperse' is yes,  it's
# default value is computed so that it generates an optimal configuration.
# An option 'force' can be used, in case the brick_dirs specified are
# some mountpoints and must be used anyway.



[volume]
action=create
volname=glustervol
transport=tcp,rdma
# replica=yes
# replica_count=2
# arbiter_count=2
disperse=yes
disperse_count=0
redundancy_count=2
force=yes


#-----------------------------------

# IMP: If only back-end setup is to be done but not GlusterFs
# deployment omit the following section

# Specifies the client hosts and client_mount_points to mount the gluster
# volume created.
# 'action' option is to be specified for the framework to understand
# what action is to be done.
# The choices are: ['mount', 'unmount']
# 'hosts' field is mandatory.
# The option 'fstype' specifies how gluster volume is to be mounted.
# Choices are: [glusterfs, nfs] (Default is glusterfs)
# Each client can have different types of volume mount. Just specify it comma
# seperated.

# Option 'client_mount_points' specifies where the clients are to be mounted
# in each host. Each host can have a seperate mountpoint, in which case it will
# be given comma seperated or else every mountpoint can have a mountpoint of the
# same name. If 'client_mount_points'
# are not specified, default will be taken as /mnt/gluster
# for all the hosts


[clients]
action=mount
hosts=10.70.46.13
fstype=glusterfs
client_mount_points=/mnt/gluster
#-----------------------------------

# 'snapshot' section can be used if the user wants to create or delete
# a snapshot.
# The option 'action' is to be used to specify which snapshot action is to be
# executed.
# The choices are [create, delete, clone, config, and restore]

# The name of the snapshot can be specified as the value to the snapname option.
# If the action is create the name of the volume is to specified as the value
# to the option 'volname'.(If not specified under the volume section).

# [snapshot]
# action=create
# snapname=glustersnap

